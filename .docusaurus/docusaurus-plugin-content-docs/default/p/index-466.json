{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/","label":"Introduction","docId":"intro","unlisted":false},{"type":"category","label":"Module 1 – ROS2","items":[{"type":"link","href":"/module-1-ros2/","label":"Module 1 ROS-2","docId":"module-1-ros2/module-1-index","unlisted":false},{"type":"link","href":"/module-1-ros2/installation-setup","label":"ROS 2 Installation and Setup","docId":"module-1-ros2/installation-setup","unlisted":false},{"type":"link","href":"/module-1-ros2/nodes-topics-services","label":"Nodes, Topics, Services","docId":"module-1-ros2/nodes-topics-services","unlisted":false},{"type":"link","href":"/module-1-ros2/practical-exercises","label":"Practical Exercises - ROS 2 Fundamentals","docId":"module-1-ros2/practical-exercises","unlisted":false},{"type":"link","href":"/module-1-ros2/rclpy-basics","label":"rclpy Basics","docId":"module-1-ros2/rclpy-basics","unlisted":false},{"type":"link","href":"/module-1-ros2/urdf-description","label":"URDF Description","docId":"module-1-ros2/urdf-description","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2 – Digital Twin","items":[{"type":"link","href":"/module-2-digital-twin/","label":"Module 2 Digital Twin","docId":"module-2-digital-twin/module-2-index","unlisted":false},{"type":"link","href":"/module-2-digital-twin/gazebo-simulation","label":"Gazebo Simulation","docId":"module-2-digital-twin/gazebo-simulation","unlisted":false},{"type":"link","href":"/module-2-digital-twin/gazebo-world-setup","label":"Gazebo World Setup and Configuration","docId":"module-2-digital-twin/gazebo-world-setup","unlisted":false},{"type":"link","href":"/module-2-digital-twin/physics-collisions","label":"Physics and Collisions","docId":"module-2-digital-twin/physics-collisions","unlisted":false},{"type":"link","href":"/module-2-digital-twin/practical-exercises","label":"Practical Exercises - Digital Twin Simulation","docId":"module-2-digital-twin/practical-exercises","unlisted":false},{"type":"link","href":"/module-2-digital-twin/sensor-simulation","label":"Sensor Simulation","docId":"module-2-digital-twin/sensor-simulation","unlisted":false},{"type":"link","href":"/module-2-digital-twin/unity-scene-setup","label":"Unity Scene Setup and Physics Configuration","docId":"module-2-digital-twin/unity-scene-setup","unlisted":false},{"type":"link","href":"/module-2-digital-twin/unity-visualization","label":"Unity Visualization","docId":"module-2-digital-twin/unity-visualization","unlisted":false},{"type":"link","href":"/module-2-digital-twin/urdf-validation","label":"URDF Model Creation and Validation","docId":"module-2-digital-twin/urdf-validation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3 – AI Perception","items":[{"type":"link","href":"/module-3-ai-perception/","label":"Module 3 AI Perception","docId":"module-3-ai-perception/module-3-index","unlisted":false},{"type":"link","href":"/module-3-ai-perception/installation-setup","label":"Isaac Sim Installation and Setup","docId":"module-3-ai-perception/installation-setup","unlisted":false},{"type":"link","href":"/module-3-ai-perception/isaac-sim","label":"Isaac Sim Fundamentals","docId":"module-3-ai-perception/isaac-sim","unlisted":false},{"type":"link","href":"/module-3-ai-perception/isaac-sim-fundamentals","label":"Isaac Sim Fundamentals","docId":"module-3-ai-perception/isaac-sim-fundamentals","unlisted":false},{"type":"link","href":"/module-3-ai-perception/object-detection-localization","label":"Object Detection and Localization Examples","docId":"module-3-ai-perception/object-detection-localization","unlisted":false},{"type":"link","href":"/module-3-ai-perception/navigation-planning-obstacle-avoidance","label":"Navigation Planning and Obstacle Avoidance Examples","docId":"module-3-ai-perception/navigation-planning-obstacle-avoidance","unlisted":false},{"type":"link","href":"/module-3-ai-perception/nav2-locomotion","label":"Nav2 for Humanoid Locomotion","docId":"module-3-ai-perception/nav2-locomotion","unlisted":false},{"type":"link","href":"/module-3-ai-perception/perception-navigation-pipeline-diagrams","label":"Perception and Navigation Pipeline Diagrams","docId":"module-3-ai-perception/perception-navigation-pipeline-diagrams","unlisted":false},{"type":"link","href":"/module-3-ai-perception/practical-exercises-isaac-ai","label":"Practical Exercises with Isaac AI Components","docId":"module-3-ai-perception/practical-exercises-isaac-ai","unlisted":false},{"type":"link","href":"/module-3-ai-perception/vslam-navigation","label":"VSLAM and Navigation","docId":"module-3-ai-perception/vslam-navigation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4 – VLA","items":[{"type":"link","href":"/module-4-vla/","label":"Module 4 VLA","docId":"module-4-vla/module-4-index","unlisted":false},{"type":"link","href":"/module-4-vla/summary","label":"Summary: Physical AI & Humanoid Robotics Book","docId":"module-4-vla/summary","unlisted":false},{"type":"link","href":"/module-4-vla/humanoid-locomotion-control","label":"Humanoid Locomotion and Control","docId":"module-4-vla/humanoid-locomotion-control","unlisted":false},{"type":"link","href":"/module-4-vla/isaac-ros-integration","label":"Isaac ROS Integration","docId":"module-4-vla/isaac-ros-integration","unlisted":false},{"type":"link","href":"/module-4-vla/isaac-sim-fundamentals","label":"Isaac Sim Fundamentals","docId":"module-4-vla/isaac-sim-fundamentals","unlisted":false},{"type":"link","href":"/module-4-vla/llm-planning","label":"LLM Planning for Robotics","docId":"module-4-vla/llm-planning","unlisted":false},{"type":"link","href":"/module-4-vla/multimodal-perception","label":"Multimodal Perception","docId":"module-4-vla/multimodal-perception","unlisted":false},{"type":"link","href":"/module-4-vla/vla-architecture-diagrams","label":"VLA Architecture Diagrams","docId":"module-4-vla/vla-architecture-diagrams","unlisted":false},{"type":"link","href":"/module-4-vla/vslam-navigation","label":"VSLAM and Navigation","docId":"module-4-vla/vslam-navigation","unlisted":false},{"type":"link","href":"/module-4-vla/whisper-speech","label":"Whisper Speech Processing","docId":"module-4-vla/whisper-speech","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"capstone-project/autonomous-humanoid":{"id":"capstone-project/autonomous-humanoid","title":"Autonomous Humanoid Project","description":""},"capstone-project/index":{"id":"capstone-project/index","title":"Capstone Overview","description":""},"intro":{"id":"intro","title":"Introduction","description":"<!-- ---","sidebar":"tutorialSidebar"},"module-1-ros2/installation-setup":{"id":"module-1-ros2/installation-setup","title":"ROS 2 Installation and Setup","description":"This section provides comprehensive instructions for installing and setting up ROS 2 (Humble Hawksbill) for use with humanoid robotics applications. Following these steps will prepare your development environment for the exercises in this book.","sidebar":"tutorialSidebar"},"module-1-ros2/module-1-index":{"id":"module-1-ros2/module-1-index","title":"Module 1 ROS-2","description":"Welcome to the first module of the Physical AI & Humanoid Robotics book! In this module, you'll learn about ROS 2 (Robot Operating System 2), the foundational middleware that enables communication and coordination in robotic systems.","sidebar":"tutorialSidebar"},"module-1-ros2/nodes-topics-services":{"id":"module-1-ros2/nodes-topics-services","title":"Nodes, Topics, Services","description":"In this section, we'll explore the fundamental communication patterns in ROS 2: nodes, topics, and services. These concepts form the backbone of robotic applications and enable different components to work together seamlessly.","sidebar":"tutorialSidebar"},"module-1-ros2/practical-exercises":{"id":"module-1-ros2/practical-exercises","title":"Practical Exercises - ROS 2 Fundamentals","description":"This section provides hands-on exercises to reinforce the concepts learned in the ROS 2 module. Complete these exercises to gain practical experience with ROS 2 nodes, topics, services, and URDF.","sidebar":"tutorialSidebar"},"module-1-ros2/rclpy-basics":{"id":"module-1-ros2/rclpy-basics","title":"rclpy Basics","description":"rclpy is the Python client library for ROS 2. It provides the Python API for developing ROS 2 applications, allowing you to create nodes, publish/subscribe to topics, provide/call services, and interact with other ROS 2 concepts.","sidebar":"tutorialSidebar"},"module-1-ros2/urdf-description":{"id":"module-1-ros2/urdf-description","title":"URDF Description","description":"URDF (Unified Robot Description Format) is an XML format used to describe robot models in ROS. It defines the physical and visual properties of a robot, including its links, joints, and other components. URDF is essential for simulating robots in Gazebo and visualizing them in RViz.","sidebar":"tutorialSidebar"},"module-2-digital-twin/gazebo-simulation":{"id":"module-2-digital-twin/gazebo-simulation","title":"Gazebo Simulation","description":"Gazebo is the standard simulation environment for ROS and provides a powerful physics engine for realistic robot simulation. This section covers setting up Gazebo, creating simulation worlds, and integrating with ROS 2.","sidebar":"tutorialSidebar"},"module-2-digital-twin/gazebo-world-setup":{"id":"module-2-digital-twin/gazebo-world-setup","title":"Gazebo World Setup and Configuration","description":"Setting up realistic and functional simulation environments is crucial for effective digital twin development. This section covers creating and configuring Gazebo worlds for humanoid robotics applications.","sidebar":"tutorialSidebar"},"module-2-digital-twin/module-2-index":{"id":"module-2-digital-twin/module-2-index","title":"Module 2 Digital Twin","description":"Welcome to the Digital Twin module! This module focuses on creating and validating virtual representations of physical robots, enabling safe testing and iterative development without requiring physical hardware.","sidebar":"tutorialSidebar"},"module-2-digital-twin/physics-collisions":{"id":"module-2-digital-twin/physics-collisions","title":"Physics and Collisions","description":"Understanding physics and collision properties is crucial for creating realistic digital twins. This section covers the principles of physics simulation and collision detection in both Gazebo and Unity environments.","sidebar":"tutorialSidebar"},"module-2-digital-twin/practical-exercises":{"id":"module-2-digital-twin/practical-exercises","title":"Practical Exercises - Digital Twin Simulation","description":"This section provides hands-on exercises to reinforce the concepts learned in the Digital Twin module. Complete these exercises to gain practical experience with Gazebo and Unity simulation environments.","sidebar":"tutorialSidebar"},"module-2-digital-twin/sensor-simulation":{"id":"module-2-digital-twin/sensor-simulation","title":"Sensor Simulation","description":"Sensor simulation is a critical component of digital twin technology, enabling robots to perceive their virtual environment just as they would in the real world. This section covers simulating various types of sensors in both Gazebo and Unity environments.","sidebar":"tutorialSidebar"},"module-2-digital-twin/unity-scene-setup":{"id":"module-2-digital-twin/unity-scene-setup","title":"Unity Scene Setup and Physics Configuration","description":"Unity provides a powerful environment for creating high-fidelity digital twins with advanced graphics and physics capabilities. This section covers setting up Unity scenes for humanoid robotics simulation with proper physics configuration.","sidebar":"tutorialSidebar"},"module-2-digital-twin/unity-visualization":{"id":"module-2-digital-twin/unity-visualization","title":"Unity Visualization","description":"Unity provides a powerful game engine environment for high-fidelity robot simulation and visualization. While Gazebo is the standard for ROS simulation, Unity offers advanced graphics capabilities and a rich ecosystem for creating detailed digital twins.","sidebar":"tutorialSidebar"},"module-2-digital-twin/urdf-validation":{"id":"module-2-digital-twin/urdf-validation","title":"URDF Model Creation and Validation","description":"Creating accurate URDF models is fundamental to successful digital twin implementation. This section covers best practices for creating URDF models and validating them for use in simulation environments.","sidebar":"tutorialSidebar"},"module-3-ai-perception/installation-setup":{"id":"module-3-ai-perception/installation-setup","title":"Isaac Sim Installation and Setup","description":"This section provides comprehensive instructions for installing and setting up NVIDIA Isaac Sim for robotics perception and navigation applications.","sidebar":"tutorialSidebar"},"module-3-ai-perception/isaac-sim":{"id":"module-3-ai-perception/isaac-sim","title":"Isaac Sim Fundamentals","description":"NVIDIA Isaac Sim is a high-fidelity simulation environment built on NVIDIA Omniverse, designed for developing, testing, and validating AI-based robotics applications. This section covers the fundamentals of Isaac Sim and its role in robotics development.","sidebar":"tutorialSidebar"},"module-3-ai-perception/isaac-sim-fundamentals":{"id":"module-3-ai-perception/isaac-sim-fundamentals","title":"Isaac Sim Fundamentals","description":"Isaac Sim is NVIDIA's high-fidelity simulation environment built on the Omniverse platform, designed specifically for developing, testing, and validating AI-based robotics applications. This section covers the core concepts and fundamentals of Isaac Sim.","sidebar":"tutorialSidebar"},"module-3-ai-perception/module-3-index":{"id":"module-3-ai-perception/module-3-index","title":"Module 3 AI Perception","description":"Welcome to Module 3 of the Physical AI & Humanoid Robotics book! This module focuses on the AI components that power modern robotics: perception, navigation, and intelligent decision-making using NVIDIA Isaac technologies.","sidebar":"tutorialSidebar"},"module-3-ai-perception/nav2-locomotion":{"id":"module-3-ai-perception/nav2-locomotion","title":"Nav2 for Humanoid Locomotion","description":"Navigation 2 (Nav2) is the ROS 2 navigation stack that enables autonomous navigation for robots. For humanoid robots, Nav2 requires special configuration to handle the unique challenges of bipedal locomotion. This section covers configuring and using Nav2 for humanoid robot navigation.","sidebar":"tutorialSidebar"},"module-3-ai-perception/navigation-planning-obstacle-avoidance":{"id":"module-3-ai-perception/navigation-planning-obstacle-avoidance","title":"Navigation Planning and Obstacle Avoidance Examples","description":"This section covers navigation planning and obstacle avoidance techniques for humanoid robots using AI-powered perception and navigation systems. We'll explore how to integrate perception data with navigation planning for safe and efficient robot movement.","sidebar":"tutorialSidebar"},"module-3-ai-perception/object-detection-localization":{"id":"module-3-ai-perception/object-detection-localization","title":"Object Detection and Localization Examples","description":"This section provides practical examples of object detection and localization using NVIDIA Isaac technologies, demonstrating how AI-powered perception systems work in robotics applications.","sidebar":"tutorialSidebar"},"module-3-ai-perception/perception-navigation-pipeline-diagrams":{"id":"module-3-ai-perception/perception-navigation-pipeline-diagrams","title":"Perception and Navigation Pipeline Diagrams","description":"This section describes the diagrams that illustrate the perception and navigation pipeline for humanoid robots using NVIDIA Isaac technologies. These diagrams help visualize the data flow and system architecture.","sidebar":"tutorialSidebar"},"module-3-ai-perception/practical-exercises-isaac-ai":{"id":"module-3-ai-perception/practical-exercises-isaac-ai","title":"Practical Exercises with Isaac AI Components","description":"This section provides hands-on exercises to reinforce the concepts learned about Isaac AI components for perception and navigation. These exercises will help you gain practical experience with NVIDIA Isaac technologies.","sidebar":"tutorialSidebar"},"module-3-ai-perception/vslam-navigation":{"id":"module-3-ai-perception/vslam-navigation","title":"VSLAM and Navigation","description":"Visual Simultaneous Localization and Mapping (VSLAM) is a critical technology for autonomous robots, enabling them to understand their environment and navigate without prior knowledge. This section covers VSLAM concepts and navigation techniques for humanoid robots using Isaac ROS.","sidebar":"tutorialSidebar"},"module-4-vla/humanoid-locomotion-control":{"id":"module-4-vla/humanoid-locomotion-control","title":"Humanoid Locomotion and Control","description":"Humanoid locomotion represents one of the most challenging problems in robotics, requiring sophisticated control systems to achieve stable, efficient, and human-like movement. This section covers the principles and implementation of humanoid locomotion using Isaac Sim and Isaac ROS.","sidebar":"tutorialSidebar"},"module-4-vla/isaac-ros-integration":{"id":"module-4-vla/isaac-ros-integration","title":"Isaac ROS Integration","description":"Isaac ROS is NVIDIA's collection of hardware-accelerated perception and navigation packages that bridge the gap between NVIDIA's GPU-accelerated AI capabilities and the ROS 2 robotics framework. This section covers how to integrate Isaac ROS packages with humanoid robotics systems.","sidebar":"tutorialSidebar"},"module-4-vla/isaac-sim-fundamentals":{"id":"module-4-vla/isaac-sim-fundamentals","title":"Isaac Sim Fundamentals","description":"Isaac Sim is NVIDIA's high-fidelity simulation environment built on the Omniverse platform, designed specifically for developing, testing, and validating AI-based robotics applications. This section covers the core concepts and fundamentals of Isaac Sim.","sidebar":"tutorialSidebar"},"module-4-vla/llm-planning":{"id":"module-4-vla/llm-planning","title":"LLM Planning for Robotics","description":"Large Language Models (LLMs) play a crucial role in robotics by enabling natural language understanding, task planning, and high-level decision making. This section covers how to integrate LLMs with humanoid robots for intelligent task planning and execution.","sidebar":"tutorialSidebar"},"module-4-vla/module-4-index":{"id":"module-4-vla/module-4-index","title":"Module 4 VLA","description":"Welcome to Module 4 of the Physical AI & Humanoid Robotics book! This module focuses on Vision-Language-Action (VLA) systems that enable humanoid robots to understand natural language commands and execute complex physical tasks in the real world.","sidebar":"tutorialSidebar"},"module-4-vla/multimodal-perception":{"id":"module-4-vla/multimodal-perception","title":"Multimodal Perception","description":"Multimodal perception refers to the integration of multiple sensory modalities (vision, language, and action) to create a comprehensive understanding of the environment and enable intelligent robot behavior. This section covers the integration of visual, linguistic, and motor information for humanoid robotics.","sidebar":"tutorialSidebar"},"module-4-vla/summary":{"id":"module-4-vla/summary","title":"Summary: Physical AI & Humanoid Robotics Book","description":"Project Completion Report","sidebar":"tutorialSidebar"},"module-4-vla/vla-architecture-diagrams":{"id":"module-4-vla/vla-architecture-diagrams","title":"VLA Architecture Diagrams","description":"This section provides detailed diagrams showing the Vision-Language-Action (VLA) architecture for humanoid robotics systems using Isaac Sim and Isaac ROS.","sidebar":"tutorialSidebar"},"module-4-vla/vslam-navigation":{"id":"module-4-vla/vslam-navigation","title":"VSLAM and Navigation","description":"Visual Simultaneous Localization and Mapping (VSLAM) is a critical technology for autonomous robots, enabling them to understand their environment and navigate without prior knowledge. This section covers VSLAM concepts and navigation techniques for humanoid robots using Isaac Sim and Isaac ROS.","sidebar":"tutorialSidebar"},"module-4-vla/whisper-speech":{"id":"module-4-vla/whisper-speech","title":"Whisper Speech Processing","description":"OpenAI's Whisper model is a state-of-the-art automatic speech recognition (ASR) system that can transcribe speech to text with remarkable accuracy. In this section, we'll explore how to integrate Whisper into your humanoid robot's communication system.","sidebar":"tutorialSidebar"}}}}