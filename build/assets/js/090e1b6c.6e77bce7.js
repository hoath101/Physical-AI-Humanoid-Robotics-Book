"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[763],{8149:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>_,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-3-ai-perception/vslam-navigation","title":"VSLAM and Navigation","description":"Visual Simultaneous Localization and Mapping (VSLAM) is a critical technology for autonomous robots, enabling them to understand their environment and navigate without prior knowledge. This section covers VSLAM concepts and navigation techniques for humanoid robots using Isaac ROS.","source":"@site/docs/module-3-ai-perception/vslam-navigation.md","sourceDirName":"module-3-ai-perception","slug":"/module-3-ai-perception/vslam-navigation","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/vslam-navigation","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Practical Exercises with Isaac AI Components","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/practical-exercises-isaac-ai"},"next":{"title":"Module 4 VLA","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/"}}');var t=a(4848),o=a(8453);const s={},r="VSLAM and Navigation",l={},c=[{value:"Introduction to VSLAM",id:"introduction-to-vslam",level:2},{value:"Key Components of VSLAM",id:"key-components-of-vslam",level:3},{value:"Visual SLAM Approaches",id:"visual-slam-approaches",level:2},{value:"1. Feature-Based VSLAM",id:"1-feature-based-vslam",level:3},{value:"2. Direct VSLAM",id:"2-direct-vslam",level:3},{value:"3. Semi-Direct VSLAM (SVO)",id:"3-semi-direct-vslam-svo",level:3},{value:"Popular VSLAM Systems",id:"popular-vslam-systems",level:2},{value:"ORB-SLAM",id:"orb-slam",level:3},{value:"LSD-SLAM",id:"lsd-slam",level:3},{value:"DSO (Direct Sparse Odometry)",id:"dso-direct-sparse-odometry",level:3},{value:"Isaac ROS VSLAM Integration",id:"isaac-ros-vslam-integration",level:2},{value:"Isaac ROS Visual SLAM Package",id:"isaac-ros-visual-slam-package",level:3},{value:"Integration with ROS 2",id:"integration-with-ros-2",level:3},{value:"Navigation Stack Integration",id:"navigation-stack-integration",level:2},{value:"Nav2 Architecture with VSLAM",id:"nav2-architecture-with-vslam",level:3},{value:"Navigation Configuration with VSLAM",id:"navigation-configuration-with-vslam",level:3},{value:"Navigation with VSLAM",id:"navigation-with-vslam",level:3},{value:"Isaac ROS Integration",id:"isaac-ros-integration",level:2},{value:"Isaac ROS VSLAM Packages",id:"isaac-ros-vslam-packages",level:3},{value:"VSLAM Performance Optimization",id:"vslam-performance-optimization",level:3},{value:"Humanoid Navigation Challenges",id:"humanoid-navigation-challenges",level:2},{value:"3D Navigation",id:"3d-navigation",level:3},{value:"Multi-Modal Navigation",id:"multi-modal-navigation",level:3},{value:"Performance Evaluation",id:"performance-evaluation",level:2},{value:"VSLAM Metrics",id:"vslam-metrics",level:3},{value:"Navigation Metrics",id:"navigation-metrics",level:3},{value:"Troubleshooting VSLAM Issues",id:"troubleshooting-vslam-issues",level:2},{value:"Common Problems and Solutions",id:"common-problems-and-solutions",level:3},{value:"1. Drift",id:"1-drift",level:4},{value:"2. Low Texture Environments",id:"2-low-texture-environments",level:4},{value:"3. Dynamic Objects",id:"3-dynamic-objects",level:4},{value:"Best Practices",id:"best-practices",level:2},{value:"1. Robust Initialization",id:"1-robust-initialization",level:3},{value:"2. Parameter Tuning",id:"2-parameter-tuning",level:3},{value:"3. Sensor Fusion",id:"3-sensor-fusion",level:3},{value:"4. Computational Efficiency",id:"4-computational-efficiency",level:3}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"vslam-and-navigation",children:"VSLAM and Navigation"})}),"\n",(0,t.jsx)(e.p,{children:"Visual Simultaneous Localization and Mapping (VSLAM) is a critical technology for autonomous robots, enabling them to understand their environment and navigate without prior knowledge. This section covers VSLAM concepts and navigation techniques for humanoid robots using Isaac ROS."}),"\n",(0,t.jsx)(e.h2,{id:"introduction-to-vslam",children:"Introduction to VSLAM"}),"\n",(0,t.jsx)(e.p,{children:"VSLAM combines computer vision and sensor data to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Localize"})," the robot in its environment"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Map"})," the environment in real-time"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Navigate"})," safely through the mapped space"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"key-components-of-vslam",children:"Key Components of VSLAM"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Feature Detection"}),": Identify distinctive points in images"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Feature Matching"}),": Match features between frames"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Pose Estimation"}),": Calculate robot position and orientation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Map Building"}),": Create and update environmental map"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Loop Closure"}),": Recognize previously visited locations"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"visual-slam-approaches",children:"Visual SLAM Approaches"}),"\n",(0,t.jsx)(e.h3,{id:"1-feature-based-vslam",children:"1. Feature-Based VSLAM"}),"\n",(0,t.jsx)(e.p,{children:"Relies on detecting and tracking distinctive features in the environment."}),"\n",(0,t.jsx)(e.h3,{id:"2-direct-vslam",children:"2. Direct VSLAM"}),"\n",(0,t.jsx)(e.p,{children:"Uses pixel intensities directly rather than features."}),"\n",(0,t.jsx)(e.h3,{id:"3-semi-direct-vslam-svo",children:"3. Semi-Direct VSLAM (SVO)"}),"\n",(0,t.jsx)(e.p,{children:"Combines feature-based tracking with direct methods."}),"\n",(0,t.jsx)(e.h2,{id:"popular-vslam-systems",children:"Popular VSLAM Systems"}),"\n",(0,t.jsx)(e.h3,{id:"orb-slam",children:"ORB-SLAM"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Features"}),": Real-time operation, loop closure, relocalization"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Strengths"}),": Robust, well-tested, handles monocular/stereo/RGB-D"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Weaknesses"}),": Requires texture-rich environments"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"lsd-slam",children:"LSD-SLAM"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Features"}),": Dense reconstruction, direct method"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Strengths"}),": Works in low-texture environments"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Weaknesses"}),": Computationally intensive"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"dso-direct-sparse-odometry",children:"DSO (Direct Sparse Odometry)"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Features"}),": Direct optimization, photometric calibration"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Strengths"}),": Accurate, handles exposure changes"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Weaknesses"}),": Requires good initialization"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"isaac-ros-vslam-integration",children:"Isaac ROS VSLAM Integration"}),"\n",(0,t.jsx)(e.h3,{id:"isaac-ros-visual-slam-package",children:"Isaac ROS Visual SLAM Package"}),"\n",(0,t.jsx)(e.p,{children:"The Isaac ROS Visual SLAM package provides optimized VSLAM capabilities:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# Example launch configuration\nvisual_slam_node:\n  ros__parameters:\n    enable_occupancy_grid: true\n    enable_diagnostics: false\n    occupancy_grid_resolution: 0.05\n    frame_id: "oak-d_frame"\n    base_frame: "base_link"\n    odom_frame: "odom"\n    enable_slam_visualization: true\n    enable_landmarks_view: true\n    enable_observations_view: true\n    calibration_file: "/tmp/calibration.json"\n    rescale_threshold: 2.0\n'})}),"\n",(0,t.jsx)(e.h3,{id:"integration-with-ros-2",children:"Integration with ROS 2"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:'\x3c!-- Launch file for VSLAM system --\x3e\n<launch>\n  \x3c!-- Camera driver --\x3e\n  <node pkg="camera_driver" exec="camera_node" name="camera">\n    <param name="camera_info_url" value="file://$(find-pkg-share robot_description)/config/camera.yaml"/>\n  </node>\n\n  \x3c!-- Isaac ROS Visual SLAM --\x3e\n  <node pkg="isaac_ros_visual_slam" exec="isaac_ros_visual_slam" name="visual_slam">\n    <param name="enable_occupancy_grid" value="true"/>\n    <param name="occupancy_grid_resolution" value="0.05"/>\n    <param name="frame_id" value="camera_link"/>\n    <param name="base_frame" value="base_link"/>\n  </node>\n\n  \x3c!-- Robot state publisher --\x3e\n  <node pkg="robot_state_publisher" exec="robot_state_publisher" name="robot_state_publisher">\n    <param name="robot_description" value="$(var robot_description)"/>\n  </node>\n</launch>\n'})}),"\n",(0,t.jsx)(e.h2,{id:"navigation-stack-integration",children:"Navigation Stack Integration"}),"\n",(0,t.jsx)(e.h3,{id:"nav2-architecture-with-vslam",children:"Nav2 Architecture with VSLAM"}),"\n",(0,t.jsx)(e.p,{children:"Nav2 (Navigation 2) is the ROS 2 navigation stack that works with VSLAM:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"Nav2 Stack\n\u251c\u2500\u2500 Global Planner (NavFn, A*, etc.)\n\u251c\u2500\u2500 Local Planner (DWA, TEB, etc.)\n\u251c\u2500\u2500 Controller (PID, MPC, etc.)\n\u251c\u2500\u2500 Recovery Behaviors\n\u251c\u2500\u2500 Costmap (Static & Local)\n\u2514\u2500\u2500 Behavior Trees (for task orchestration)\n"})}),"\n",(0,t.jsx)(e.h3,{id:"navigation-configuration-with-vslam",children:"Navigation Configuration with VSLAM"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# nav2_params.yaml with VSLAM integration\namcl:\n  ros__parameters:\n    use_sim_time: True\n    alpha1: 0.2\n    alpha2: 0.2\n    alpha3: 0.2\n    alpha4: 0.2\n    alpha5: 0.2\n    base_frame_id: "base_link"\n    beam_skip_distance: 0.5\n    beam_skip_error_threshold: 0.9\n    beam_skip_threshold: 0.3\n    do_beamskip: false\n    global_frame_id: "map"\n    lambda_short: 0.1\n    laser_likelihood_max_dist: 2.0\n    laser_max_range: 100.0\n    laser_min_range: -1.0\n    laser_model_type: "likelihood_field"\n    max_beams: 60\n    max_particles: 2000\n    min_particles: 500\n    odom_frame_id: "odom"\n    pf_err: 0.05\n    pf_z: 0.99\n    recovery_alpha_fast: 0.0\n    recovery_alpha_slow: 0.0\n    resample_interval: 1\n    robot_model_type: "nav2_amcl::DifferentialMotionModel"\n    save_pose_rate: 0.5\n    sigma_hit: 0.2\n    tf_broadcast: true\n    transform_tolerance: 1.0\n    update_min_a: 0.2\n    update_min_d: 0.2\n    z_hit: 0.5\n    z_max: 0.05\n    z_rand: 0.5\n    z_short: 0.05\n\nbt_navigator:\n  ros__parameters:\n    use_sim_time: True\n    global_frame: map\n    robot_base_frame: base_link\n    odom_topic: /odom\n    bt_loop_duration: 10\n    default_server_timeout: 20\n    enable_groot_monitoring: True\n    groot_zmq_publisher_port: 1666\n    groot_zmq_server_port: 1667\n    default_nav_through_poses_bt_xml: nav2_bt_navigator/navigate_through_poses_w_replanning_and_recovery.xml\n    default_nav_to_pose_bt_xml: nav2_bt_navigator/navigate_to_pose_w_replanning_and_recovery.xml\n    plugin_lib_names:\n    - nav2_compute_path_to_pose_action_bt_node\n    - nav2_compute_path_through_poses_action_bt_node\n    - nav2_smooth_path_action_bt_node\n    - nav2_follow_path_action_bt_node\n    - nav2_spin_action_bt_node\n    - nav2_wait_action_bt_node\n    - nav2_assisted_teleop_action_bt_node\n    - nav2_back_up_action_bt_node\n    - nav2_drive_on_heading_bt_node\n    - nav2_clear_costmap_service_bt_node\n    - nav2_is_stuck_condition_bt_node\n    - nav2_goal_reached_condition_bt_node\n    - nav2_goal_updated_condition_bt_node\n    - nav2_globally_consistent_condition_bt_node\n    - nav2_is_path_valid_condition_bt_node\n    - nav2_initial_pose_received_condition_bt_node\n    - nav2_reinitialize_global_localization_service_bt_node\n    - nav2_rate_controller_bt_node\n    - nav2_distance_controller_bt_node\n    - nav2_speed_controller_bt_node\n    - nav2_truncate_path_action_bt_node\n    - nav2_truncate_path_local_action_bt_node\n    - nav2_goal_updater_node_bt_node\n    - nav2_recovery_node_bt_node\n    - nav2_pipeline_sequence_bt_node\n    - nav2_round_robin_node_bt_node\n    - nav2_transform_available_condition_bt_node\n    - nav2_time_expired_condition_bt_node\n    - nav2_path_expiring_timer_condition\n    - nav2_distance_traveled_condition_bt_node\n    - nav2_is_battery_low_condition_bt_node\n    - nav2_navigate_through_poses_action_bt_node\n    - nav2_navigate_to_pose_action_bt_node\n    - nav2_remove_passed_goals_action_bt_node\n    - nav2_planner_selector_bt_node\n    - nav2_controller_selector_bt_node\n    - nav2_goal_checker_selector_bt_node\n    - nav2_controller_cancel_bt_node\n    - nav2_path_longer_on_approach_bt_node\n    - nav2_wait_cancel_bt_node\n    - nav2_spin_cancel_bt_node\n    - nav2_back_up_cancel_bt_node\n    - nav2_assisted_teleop_cancel_bt_node\n    - nav2_drive_on_heading_cancel_bt_node\n'})}),"\n",(0,t.jsx)(e.h3,{id:"navigation-with-vslam",children:"Navigation with VSLAM"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-cpp",children:'#include <rclcpp/rclcpp.hpp>\n#include <nav2_msgs/action/navigate_to_pose.hpp>\n#include <rclcpp_action/rclcpp_action.hpp>\n\nclass NavigationWithVSLAM : public rclcpp::Node\n{\npublic:\n    NavigationWithVSLAM() : Node("nav_with_vslam")\n    {\n        // Create action client for navigation\n        nav_client_ = rclcpp_action::create_client<nav2_msgs::action::NavigateToPose>(\n            this, "navigate_to_pose"\n        );\n\n        // Subscribe to VSLAM pose\n        vslam_sub_ = this->create_subscription<geometry_msgs::msg::PoseStamped>(\n            "visual_slam/pose", 10,\n            std::bind(&NavigationWithVSLAM::vslamPoseCallback, this, std::placeholders::_1)\n        );\n    }\n\n    void navigateToGoal(double x, double y, double theta)\n    {\n        // Wait for action server\n        if (!nav_client_->wait_for_action_server(std::chrono::seconds(5))) {\n            RCLCPP_ERROR(this->get_logger(), "Navigation action server not available");\n            return;\n        }\n\n        // Create goal\n        auto goal = nav2_msgs::action::NavigateToPose::Goal();\n        goal.pose.header.frame_id = "map";\n        goal.pose.header.stamp = this->now();\n        goal.pose.pose.position.x = x;\n        goal.pose.pose.position.y = y;\n        goal.pose.pose.position.z = 0.0;\n\n        // Convert theta to quaternion\n        double s = sin(theta/2);\n        double c = cos(theta/2);\n        goal.pose.pose.orientation.x = 0.0;\n        goal.pose.pose.orientation.y = 0.0;\n        goal.pose.pose.orientation.z = s;\n        goal.pose.pose.orientation.w = c;\n\n        // Send goal\n        auto send_goal_options = rclcpp_action::Client<nav2_msgs::action::NavigateToPose>::SendGoalOptions();\n        send_goal_options.result_callback =\n            [this](const rclcpp_action::ClientGoalHandle<nav2_msgs::action::NavigateToPose>::WrappedResult& result) {\n                if (result.code == rclcpp_action::ResultCode::SUCCEEDED) {\n                    RCLCPP_INFO(this->get_logger(), "Navigation succeeded!");\n                } else {\n                    RCLCPP_ERROR(this->get_logger(), "Navigation failed!");\n                }\n            };\n\n        nav_client_->async_send_goal(goal, send_goal_options);\n    }\n\nprivate:\n    void vslamPoseCallback(const geometry_msgs::msg::PoseStamped::SharedPtr msg)\n    {\n        // Update robot\'s pose in the navigation system\n        current_pose_ = *msg;\n\n        // This pose can be used for localization in the navigation stack\n        RCLCPP_DEBUG(this->get_logger(),\n            "Received VSLAM pose: (%.2f, %.2f)",\n            msg->pose.position.x, msg->pose.position.y);\n    }\n\n    rclcpp_action::Client<nav2_msgs::action::NavigateToPose>::SharedPtr nav_client_;\n    rclcpp::Subscription<geometry_msgs::msg::PoseStamped>::SharedPtr vslam_sub_;\n    geometry_msgs::msg::PoseStamped current_pose_;\n};\n'})}),"\n",(0,t.jsx)(e.h2,{id:"isaac-ros-integration",children:"Isaac ROS Integration"}),"\n",(0,t.jsx)(e.h3,{id:"isaac-ros-vslam-packages",children:"Isaac ROS VSLAM Packages"}),"\n",(0,t.jsx)(e.p,{children:"NVIDIA Isaac ROS provides optimized VSLAM implementations:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# Isaac ROS VSLAM launch\nlaunch:\n  - package: "isaac_ros_visual_slam"\n    executable: "isaac_ros_visual_slam"\n    name: "visual_slam"\n    parameters:\n      - "enable_occupancy_grid": True\n      - "occupancy_grid_resolution": 0.05\n      - "frame_id": "camera_link"\n      - "base_frame": "base_link"\n      - "enable_slam_visualization": True\n'})}),"\n",(0,t.jsx)(e.h3,{id:"vslam-performance-optimization",children:"VSLAM Performance Optimization"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-cpp",children:'// Optimized VSLAM node with performance considerations\nclass OptimizedVSLAMNode : public rclcpp::Node\n{\npublic:\n    OptimizedVSLAMNode() : Node("optimized_vslam")\n    {\n        // Use intra-process communication when possible\n        rclcpp::QoS qos(10);\n        qos.best_effort();\n\n        image_sub_ = this->create_subscription<sensor_msgs::msg::Image>(\n            "camera/image_raw", qos,\n            std::bind(&OptimizedVSLAMNode::imageCallback, this, std::placeholders::_1)\n        );\n\n        // Throttle processing if needed\n        processing_rate_ = this->declare_parameter("processing_rate", 10.0);\n        timer_ = this->create_wall_timer(\n            std::chrono::milliseconds(static_cast<int>(1000.0 / processing_rate_)),\n            std::bind(&OptimizedVSLAMNode::processCallback, this)\n        );\n    }\n\nprivate:\n    void imageCallback(const sensor_msgs::msg::Image::SharedPtr msg)\n    {\n        // Store image for processing at fixed rate\n        latest_image_ = msg;\n        image_available_ = true;\n    }\n\n    void processCallback()\n    {\n        if (!image_available_) return;\n\n        // Process with VSLAM\n        processVSLAM(latest_image_);\n        image_available_ = false;\n    }\n\n    rclcpp::Subscription<sensor_msgs::msg::Image>::SharedPtr image_sub_;\n    rclcpp::TimerBase::SharedPtr timer_;\n    sensor_msgs::msg::Image::SharedPtr latest_image_;\n    bool image_available_ = false;\n    double processing_rate_;\n};\n'})}),"\n",(0,t.jsx)(e.h2,{id:"humanoid-navigation-challenges",children:"Humanoid Navigation Challenges"}),"\n",(0,t.jsx)(e.h3,{id:"3d-navigation",children:"3D Navigation"}),"\n",(0,t.jsx)(e.p,{children:"Humanoid robots require 3D navigation capabilities:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-cpp",children:"// 3D navigation for humanoid robots\nclass Humanoid3DNavigator\n{\npublic:\n    void navigate3D(const geometry_msgs::msg::Pose& target)\n    {\n        // Plan 3D path considering robot's height and step capabilities\n        auto path3d = plan3DPath(current_pose_, target);\n\n        // Execute path with balance considerations\n        executePathWithBalance(path3d);\n    }\n\nprivate:\n    std::vector<geometry_msgs::msg::Pose> plan3DPath(\n        const geometry_msgs::msg::Pose& start,\n        const geometry_msgs::msg::Pose& goal)\n    {\n        // Implement 3D path planning considering:\n        // - Robot's height and reach\n        // - Stair navigation\n        // - Obstacle avoidance in 3D space\n        // - Balance constraints\n    }\n\n    void executePathWithBalance(const std::vector<geometry_msgs::msg::Pose>& path)\n    {\n        // Execute path while maintaining balance\n        // This involves:\n        // - Walking pattern generation\n        // - Balance control\n        // - Step planning\n    }\n};\n"})}),"\n",(0,t.jsx)(e.h3,{id:"multi-modal-navigation",children:"Multi-Modal Navigation"}),"\n",(0,t.jsx)(e.p,{children:"Combine different navigation modes:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-cpp",children:"enum NavigationMode {\n    WALKING,\n    CLIMBING,\n    CRAWLING,\n    MANIPULATION_ASSISTED\n};\n\nclass MultiModalNavigator\n{\npublic:\n    void navigateWithMode(const geometry_msgs::msg::Pose& target, NavigationMode mode)\n    {\n        switch (mode) {\n            case WALKING:\n                executeWalkingNavigation(target);\n                break;\n            case CLIMBING:\n                executeClimbingNavigation(target);\n                break;\n            case CRAWLING:\n                executeCrawlingNavigation(target);\n                break;\n            case MANIPULATION_ASSISTED:\n                executeManipulationAssistedNavigation(target);\n                break;\n        }\n    }\n\nprivate:\n    void executeWalkingNavigation(const geometry_msgs::msg::Pose& target);\n    void executeClimbingNavigation(const geometry_msgs::msg::Pose& target);\n    void executeCrawlingNavigation(const geometry_msgs::msg::Pose& target);\n    void executeManipulationAssistedNavigation(const geometry_msgs::msg::Pose& target);\n};\n"})}),"\n",(0,t.jsx)(e.h2,{id:"performance-evaluation",children:"Performance Evaluation"}),"\n",(0,t.jsx)(e.h3,{id:"vslam-metrics",children:"VSLAM Metrics"}),"\n",(0,t.jsx)(e.p,{children:"Evaluate VSLAM performance with:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Absolute Trajectory Error (ATE)"}),": Difference between estimated and ground truth trajectory"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Relative Pose Error (RPE)"}),": Error in relative motion estimates"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Processing Time"}),": Real-time performance metrics"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Map Accuracy"}),": Quality of reconstructed environment"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"navigation-metrics",children:"Navigation Metrics"}),"\n",(0,t.jsx)(e.p,{children:"For navigation performance:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Success Rate"}),": Percentage of successful goal reaches"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Path Efficiency"}),": Actual path length vs optimal path"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Time to Goal"}),": Navigation completion time"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Safety"}),": Number of collisions or near-misses"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"troubleshooting-vslam-issues",children:"Troubleshooting VSLAM Issues"}),"\n",(0,t.jsx)(e.h3,{id:"common-problems-and-solutions",children:"Common Problems and Solutions"}),"\n",(0,t.jsx)(e.h4,{id:"1-drift",children:"1. Drift"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Problem"}),": Accumulated pose errors over time\n",(0,t.jsx)(e.strong,{children:"Solutions"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Implement loop closure detection"}),"\n",(0,t.jsx)(e.li,{children:"Use sensor fusion with IMU/odometry"}),"\n",(0,t.jsx)(e.li,{children:"Regular relocalization against known features"}),"\n"]}),"\n",(0,t.jsx)(e.h4,{id:"2-low-texture-environments",children:"2. Low Texture Environments"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Problem"}),": Insufficient features for tracking\n",(0,t.jsx)(e.strong,{children:"Solutions"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Use direct methods (LSD-SLAM, DSO)"}),"\n",(0,t.jsx)(e.li,{children:"Add artificial markers or fiducials"}),"\n",(0,t.jsx)(e.li,{children:"Combine with other sensors (LIDAR, IMU)"}),"\n"]}),"\n",(0,t.jsx)(e.h4,{id:"3-dynamic-objects",children:"3. Dynamic Objects"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Problem"}),": Moving objects affecting map/pose estimation\n",(0,t.jsx)(e.strong,{children:"Solutions"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Implement dynamic object detection and filtering"}),"\n",(0,t.jsx)(e.li,{children:"Use semantic segmentation to identify static objects"}),"\n",(0,t.jsx)(e.li,{children:"Temporal consistency checks"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,t.jsx)(e.h3,{id:"1-robust-initialization",children:"1. Robust Initialization"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Ensure good initial pose estimate"}),"\n",(0,t.jsx)(e.li,{children:"Verify camera calibration"}),"\n",(0,t.jsx)(e.li,{children:"Check lighting conditions"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"2-parameter-tuning",children:"2. Parameter Tuning"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Adjust parameters based on environment"}),"\n",(0,t.jsx)(e.li,{children:"Monitor performance metrics"}),"\n",(0,t.jsx)(e.li,{children:"Use adaptive parameters when possible"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"3-sensor-fusion",children:"3. Sensor Fusion"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Combine VSLAM with other sensors"}),"\n",(0,t.jsx)(e.li,{children:"Use IMU for motion prediction"}),"\n",(0,t.jsx)(e.li,{children:"Integrate with wheel odometry"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"4-computational-efficiency",children:"4. Computational Efficiency"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Optimize feature detection and matching"}),"\n",(0,t.jsx)(e.li,{children:"Use appropriate image resolution"}),"\n",(0,t.jsx)(e.li,{children:"Implement multi-threading where possible"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Isaac ROS Visual SLAM provides a powerful foundation for robot localization and mapping, especially when combined with other Isaac ROS perception packages for a complete AI-powered robotics solution."})]})}function _(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>s,x:()=>r});var i=a(6540);const t={},o=i.createContext(t);function s(n){const e=i.useContext(o);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:s(n.components),i.createElement(o.Provider,{value:e},n.children)}}}]);