<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-3-ai-perception/object-detection-localization" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Object Detection and Localization Examples | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://hoath101.github.io/Physical-AI-Humanoid-Robotics-Book/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://hoath101.github.io/Physical-AI-Humanoid-Robotics-Book/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://hoath101.github.io/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/object-detection-localization"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Object Detection and Localization Examples | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="This section provides practical examples of object detection and localization using NVIDIA Isaac technologies, demonstrating how AI-powered perception systems work in robotics applications."><meta data-rh="true" property="og:description" content="This section provides practical examples of object detection and localization using NVIDIA Isaac technologies, demonstrating how AI-powered perception systems work in robotics applications."><link data-rh="true" rel="icon" href="/Physical-AI-Humanoid-Robotics-Book/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://hoath101.github.io/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/object-detection-localization"><link data-rh="true" rel="alternate" href="https://hoath101.github.io/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/object-detection-localization" hreflang="en"><link data-rh="true" rel="alternate" href="https://hoath101.github.io/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/object-detection-localization" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Object Detection and Localization Examples","item":"https://hoath101.github.io/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/object-detection-localization"}]}</script><link rel="stylesheet" href="/Physical-AI-Humanoid-Robotics-Book/assets/css/styles.30727653.css">
<script src="/Physical-AI-Humanoid-Robotics-Book/assets/js/runtime~main.ff7ca8d7.js" defer="defer"></script>
<script src="/Physical-AI-Humanoid-Robotics-Book/assets/js/main.743fb04c.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Physical-AI-Humanoid-Robotics-Book/"><div class="navbar__logo"><img src="/Physical-AI-Humanoid-Robotics-Book/img/logo.jpg" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Physical-AI-Humanoid-Robotics-Book/img/logo.jpg" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/Physical-AI-Humanoid-Robotics-Book/docs/">Book</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/hoath101/physical-ai-humanoid-robotics-book" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Physical-AI-Humanoid-Robotics-Book/docs/"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-1-ros2/"><span title="Module 1 – ROS2" class="categoryLinkLabel_W154">Module 1 – ROS2</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-2-digital-twin/"><span title="Module 2 – Digital Twin" class="categoryLinkLabel_W154">Module 2 – Digital Twin</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/"><span title="Module 3 – AI Perception" class="categoryLinkLabel_W154">Module 3 – AI Perception</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/"><span title="Module 3 AI Perception" class="linkLabel_WmDU">Module 3 AI Perception</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/installation-setup"><span title="Isaac Sim Installation and Setup" class="linkLabel_WmDU">Isaac Sim Installation and Setup</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/isaac-sim"><span title="Isaac Sim Fundamentals" class="linkLabel_WmDU">Isaac Sim Fundamentals</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/isaac-sim-fundamentals"><span title="Isaac Sim Fundamentals" class="linkLabel_WmDU">Isaac Sim Fundamentals</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/object-detection-localization"><span title="Object Detection and Localization Examples" class="linkLabel_WmDU">Object Detection and Localization Examples</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/navigation-planning-obstacle-avoidance"><span title="Navigation Planning and Obstacle Avoidance Examples" class="linkLabel_WmDU">Navigation Planning and Obstacle Avoidance Examples</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/nav2-locomotion"><span title="Nav2 for Humanoid Locomotion" class="linkLabel_WmDU">Nav2 for Humanoid Locomotion</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/perception-navigation-pipeline-diagrams"><span title="Perception and Navigation Pipeline Diagrams" class="linkLabel_WmDU">Perception and Navigation Pipeline Diagrams</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/practical-exercises-isaac-ai"><span title="Practical Exercises with Isaac AI Components" class="linkLabel_WmDU">Practical Exercises with Isaac AI Components</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/vslam-navigation"><span title="VSLAM and Navigation" class="linkLabel_WmDU">VSLAM and Navigation</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/"><span title="Module 4 – VLA" class="categoryLinkLabel_W154">Module 4 – VLA</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module 3 – AI Perception</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Object Detection and Localization Examples</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Object Detection and Localization Examples</h1></header>
<p>This section provides practical examples of object detection and localization using NVIDIA Isaac technologies, demonstrating how AI-powered perception systems work in robotics applications.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction-to-object-detection-in-robotics">Introduction to Object Detection in Robotics<a href="#introduction-to-object-detection-in-robotics" class="hash-link" aria-label="Direct link to Introduction to Object Detection in Robotics" title="Direct link to Introduction to Object Detection in Robotics" translate="no">​</a></h2>
<p>Object detection in robotics involves identifying and localizing objects in the robot&#x27;s environment. This capability is crucial for:</p>
<ul>
<li class="">Navigation and path planning</li>
<li class="">Manipulation and grasping</li>
<li class="">Scene understanding</li>
<li class="">Human-robot interaction</li>
<li class="">Autonomous decision making</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="isaac-ros-perception-pipeline">Isaac ROS Perception Pipeline<a href="#isaac-ros-perception-pipeline" class="hash-link" aria-label="Direct link to Isaac ROS Perception Pipeline" title="Direct link to Isaac ROS Perception Pipeline" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="overview-of-isaac-ros-perception-stack">Overview of Isaac ROS Perception Stack<a href="#overview-of-isaac-ros-perception-stack" class="hash-link" aria-label="Direct link to Overview of Isaac ROS Perception Stack" title="Direct link to Overview of Isaac ROS Perception Stack" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Isaac ROS Perception</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Isaac ROS Image Pipeline</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── Image Proc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── Rectification</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   └── Format Conversion</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Isaac ROS Visual SLAM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── Feature Detection</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── Pose Estimation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   └── Map Building</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Isaac ROS Object Detection</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── Deep Learning Models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── TensorRT Optimization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   └── Post-processing</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Isaac ROS Pose Estimation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── 2D-3D Correspondence</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── PnP Solvers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   └── Refinement</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└── Isaac ROS Bi3D</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ├── 3D Segmentation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ├── Depth Estimation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    └── Instance Segmentation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## Isaac ROS Object Detection Examples</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### 1. Isaac ROS DetectNet</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">DetectNet is NVIDIA&#x27;s specialized network for object detection optimized for robotics applications.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#### Basic DetectNet Node Implementation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```cpp</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;rclcpp/rclcpp.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;sensor_msgs/msg/image.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;sensor_msgs/msg/camera_info.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;isaac_ros_detectnet_interfaces/msg/detection_array.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;cv_bridge/cv_bridge.h&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;opencv2/opencv.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class IsaacDetectNetNode : public rclcpp::Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">public:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    IsaacDetectNetNode() : Node(&quot;isaac_detectnet_node&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Create subscribers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        image_sub_ = this-&gt;create_subscription&lt;sensor_msgs::msg::Image&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;image_input&quot;, 10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::bind(&amp;IsaacDetectNetNode::imageCallback, this, std::placeholders::_1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        camera_info_sub_ = this-&gt;create_subscription&lt;sensor_msgs::msg::CameraInfo&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;camera_info&quot;, 10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::bind(&amp;IsaacDetectNetNode::cameraInfoCallback, this, std::placeholders::_1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Create publisher for detections</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        detection_pub_ = this-&gt;create_publisher&lt;isaac_ros_detectnet_interfaces::msg::DetectionArray&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;detections&quot;, 10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">private:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void imageCallback(const sensor_msgs::msg::Image::SharedPtr image_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Convert ROS image to OpenCV</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv_bridge::CvImagePtr cv_ptr;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        try {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            cv_ptr = cv_bridge::toCvCopy(image_msg, sensor_msgs::image_encodings::BGR8);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        } catch (cv_bridge::Exception&amp; e) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            RCLCPP_ERROR(this-&gt;get_logger(), &quot;cv_bridge exception: %s&quot;, e.what());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Process image through DetectNet model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto detections = runDetectNetInference(cv_ptr-&gt;image);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Create detection message</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto detection_msg = createDetectionMessage(detections, image_msg-&gt;header);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Publish detections</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        detection_pub_-&gt;publish(detection_msg);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void cameraInfoCallback(const sensor_msgs::msg::CameraInfo::SharedPtr info_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        camera_info_ = *info_msg;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::vector&lt;Detection&gt; runDetectNetInference(const cv::Mat&amp; image)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // This would interface with the actual DetectNet model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // In practice, this uses TensorRT for optimized inference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::vector&lt;Detection&gt; detections;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Placeholder for actual inference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // In real implementation, this would:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 1. Preprocess image for the model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 2. Run inference using TensorRT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 3. Post-process results</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 4. Apply non-maximum suppression</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 5. Filter by confidence threshold</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return detections;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    isaac_ros_detectnet_interfaces::msg::DetectionArray createDetectionMessage(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        const std::vector&lt;Detection&gt;&amp; detections,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        const std_msgs::msg::Header&amp; header)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        isaac_ros_detectnet_interfaces::msg::DetectionArray detection_array;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        detection_array.header = header;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for (const auto&amp; detection : detections) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            isaac_ros_detectnet_interfaces::msg::Detection det_msg;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            det_msg.label = detection.label;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            det_msg.confidence = detection.confidence;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Bounding box coordinates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            det_msg.bbox.center.x = detection.center_x;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            det_msg.bbox.center.y = detection.center_y;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            det_msg.bbox.size_x = detection.width;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            det_msg.bbox.size_y = detection.height;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            detection_array.detections.push_back(det_msg);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return detection_array;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    struct Detection {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::string label;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float confidence;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float center_x, center_y;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float width, height;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    };</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Subscription&lt;sensor_msgs::msg::Image&gt;::SharedPtr image_sub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Subscription&lt;sensor_msgs::msg::CameraInfo&gt;::SharedPtr camera_info_sub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Publisher&lt;isaac_ros_detectnet_interfaces::msg::DetectionArray&gt;::SharedPtr detection_pub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sensor_msgs::msg::CameraInfo camera_info_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">};</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#### DetectNet Launch Configuration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```xml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;!-- detectnet.launch.xml --&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;launch&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;!-- Image rectification --&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;node pkg=&quot;isaac_ros_image_proc&quot; exec=&quot;isaac_ros_image_proc&quot; name=&quot;image_proc&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;param name=&quot;input_encoding&quot; value=&quot;bgr8&quot;/&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;param name=&quot;output_encoding&quot; value=&quot;bgr8&quot;/&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;/node&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;!-- DetectNet node --&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;node pkg=&quot;isaac_ros_detectnet&quot; exec=&quot;isaac_ros_detectnet&quot; name=&quot;detectnet&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;param name=&quot;model_name&quot; value=&quot;ssd_mobilenet_v2_coco&quot;/&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;param name=&quot;input_topic&quot; value=&quot;/image_rect_color&quot;/&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;param name=&quot;output_topic&quot; value=&quot;/detections&quot;/&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;param name=&quot;confidence_threshold&quot; value=&quot;0.5&quot;/&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;param name=&quot;max_objects&quot; value=&quot;10&quot;/&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;/node&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;!-- Visualization node --&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;node pkg=&quot;isaac_ros_visualization&quot; exec=&quot;detection_visualizer&quot; name=&quot;detection_visualizer&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;param name=&quot;image_topic&quot; value=&quot;/image_rect_color&quot;/&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;param name=&quot;detection_topic&quot; value=&quot;/detections&quot;/&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;param name=&quot;output_topic&quot; value=&quot;/detection_image&quot;/&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;/node&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/launch&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### 2. Isaac ROS Bi3D (3D Object Detection)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Bi3D provides 3D object detection and segmentation capabilities.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#### Bi3D Node Implementation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```cpp</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;rclcpp/rclcpp.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;sensor_msgs/msg/image.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;stereo_msgs/msg/disparity_image.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;isaac_ros_bi3d_interfaces/msg/bi3_d_inference_array.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class IsaacBi3DNode : public rclcpp::Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">public:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    IsaacBi3DNode() : Node(&quot;isaac_bi3d_node&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Subscribe to stereo image pair</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        left_sub_ = this-&gt;create_subscription&lt;sensor_msgs::msg::Image&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;left/image_rect_color&quot;, 10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::bind(&amp;IsaacBi3DNode::leftImageCallback, this, std::placeholders::_1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        right_sub_ = this-&gt;create_subscription&lt;sensor_msgs::msg::Image&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;right/image_rect_color&quot;, 10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::bind(&amp;IsaacBi3DNode::rightImageCallback, this, std::placeholders::_1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Subscribe to disparity for depth</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        disparity_sub_ = this-&gt;create_subscription&lt;stereo_msgs::msg::DisparityImage&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;disparity&quot;, 10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::bind(&amp;IsaacBi3DNode::disparityCallback, this, std::placeholders::_1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Publisher for 3D detections</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        bi3d_pub_ = this-&gt;create_publisher&lt;isaac_ros_bi3d_interfaces::msg::Bi3DInferenceArray&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;bi3d_detections&quot;, 10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">private:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void leftImageCallback(const sensor_msgs::msg::Image::SharedPtr msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (has_right_image_ &amp;&amp; has_disparity_) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            processStereoPair(msg, right_image_, disparity_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        } else {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            left_image_ = msg;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void rightImageCallback(const sensor_msgs::msg::Image::SharedPtr msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        has_right_image_ = true;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        right_image_ = msg;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (has_left_image_ &amp;&amp; has_disparity_) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            processStereoPair(left_image_, msg, disparity_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void disparityCallback(const stereo_msgs::msg::DisparityImage::SharedPtr msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        has_disparity_ = true;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        disparity_ = msg;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (has_left_image_ &amp;&amp; has_right_image_) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            processStereoPair(left_image_, right_image_, msg);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void processStereoPair(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        const sensor_msgs::msg::Image::SharedPtr left,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        const sensor_msgs::msg::Image::SharedPtr right,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        const stereo_msgs::msg::DisparityImage::SharedPtr disparity)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Run Bi3D inference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto bi3d_results = runBi3DInference(left, right);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Create 3D detection message</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto bi3d_msg = createBi3DMessage(bi3d_results, left-&gt;header);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Publish results</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        bi3d_pub_-&gt;publish(bi3d_msg);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Reset flags</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        has_left_image_ = false;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        has_right_image_ = false;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        has_disparity_ = false;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::vector&lt;Bi3DResult&gt; runBi3DInference(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        const sensor_msgs::msg::Image::SharedPtr left,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        const sensor_msgs::msg::Image::SharedPtr right)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Placeholder for actual Bi3D inference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // This would:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 1. Process stereo images through Bi3D network</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 2. Generate 3D segmentation masks</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 3. Extract 3D bounding boxes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 4. Estimate 3D poses</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::vector&lt;Bi3DResult&gt; results;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Implementation would go here</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return results;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    isaac_ros_bi3d_interfaces::msg::Bi3DInferenceArray createBi3DMessage(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        const std::vector&lt;Bi3DResult&gt;&amp; results,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        const std_msgs::msg::Header&amp; header)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        isaac_ros_bi3d_interfaces::msg::Bi3DInferenceArray bi3d_array;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        bi3d_array.header = header;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for (const auto&amp; result : results) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            isaac_ros_bi3d_interfaces::msg::Bi3DInference bi3d_msg;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            bi3d_msg.class_id = result.class_id;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            bi3d_msg.confidence = result.confidence;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // 3D bounding box</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            bi3d_msg.bounding_box_3d.center.position.x = result.center_x;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            bi3d_msg.bounding_box_3d.center.position.y = result.center_y;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            bi3d_msg.bounding_box_3d.center.position.z = result.center_z;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Convert Euler angles to quaternion</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            tf2::Quaternion q;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            q.setRPY(result.roll, result.pitch, result.yaw);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            bi3d_msg.bounding_box_3d.center.orientation.x = q.x();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            bi3d_msg.bounding_box_3d.center.orientation.y = q.y();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            bi3d_msg.bounding_box_3d.center.orientation.z = q.z();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            bi3d_msg.bounding_box_3d.center.orientation.w = q.w();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            bi3d_msg.bounding_box_3d.size.x = result.size_x;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            bi3d_msg.bounding_box_3d.size.y = result.size_y;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            bi3d_msg.bounding_box_3d.size.z = result.size_z;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            bi3d_array.inferences.push_back(bi3d_msg);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return bi3d_array;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    struct Bi3DResult {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        int class_id;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float confidence;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float center_x, center_y, center_z;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float roll, pitch, yaw;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float size_x, size_y, size_z;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    };</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Subscription&lt;sensor_msgs::msg::Image&gt;::SharedPtr left_sub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Subscription&lt;sensor_msgs::msg::Image&gt;::SharedPtr right_sub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Subscription&lt;stereo_msgs::msg::DisparityImage&gt;::SharedPtr disparity_sub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Publisher&lt;isaac_ros_bi3d_interfaces::msg::Bi3DInferenceArray&gt;::SharedPtr bi3d_pub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sensor_msgs::msg::Image::SharedPtr left_image_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sensor_msgs::msg::Image::SharedPtr right_image_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    stereo_msgs::msg::DisparityImage::SharedPtr disparity_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    bool has_left_image_ = false;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    bool has_right_image_ = false;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    bool has_disparity_ = false;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">};</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## Object Localization Examples</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### 1. Camera-Object 3D Localization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```cpp</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;rclcpp/rclcpp.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;geometry_msgs/msg/point_stamped.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;sensor_msgs/msg/camera_info.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;isaac_ros_detectnet_interfaces/msg/detection_array.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;tf2_ros/transform_listener.h&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;tf2_geometry_msgs/tf2_geometry_msgs.h&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class ObjectLocalizationNode : public rclcpp::Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">public:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ObjectLocalizationNode() : Node(&quot;object_localization_node&quot;), tf_buffer_(this-&gt;get_clock())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        detection_sub_ = this-&gt;create_subscription&lt;isaac_ros_detectnet_interfaces::msg::DetectionArray&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;detections&quot;, 10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::bind(&amp;ObjectLocalizationNode::detectionCallback, this, std::placeholders::_1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        camera_info_sub_ = this-&gt;create_subscription&lt;sensor_msgs::msg::CameraInfo&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;camera_info&quot;, 10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::bind(&amp;ObjectLocalizationNode::cameraInfoCallback, this, std::placeholders::_1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        object_pose_pub_ = this-&gt;create_publisher&lt;geometry_msgs::msg::PointStamped&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;object_3d_position&quot;, 10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        tf_listener_ = std::make_shared&lt;tf2_ros::TransformListener&gt;(tf_buffer_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">private:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void detectionCallback(const isaac_ros_detectnet_interfaces::msg::DetectionArray::SharedPtr detections)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (!camera_info_received_ || !has_camera_to_robot_tf_) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            RCLCPP_WARN(this-&gt;get_logger(), &quot;Camera info or TF not available yet&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for (const auto&amp; detection : detections-&gt;detections) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if (detection.confidence &lt; confidence_threshold_) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                continue;  // Skip low-confidence detections</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Convert 2D bounding box center to 3D point</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            geometry_msgs::msg::PointStamped pixel_point;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            pixel_point.header = detections-&gt;header;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            pixel_point.point.x = detection.bbox.center.x;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            pixel_point.point.y = detection.bbox.center.y;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            pixel_point.point.z = 1.0;  // Placeholder depth</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Convert pixel coordinates to 3D camera frame</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            geometry_msgs::msg::PointStamped camera_point;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            camera_point = pixelToCameraFrame(pixel_point);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Transform to robot base frame</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            geometry_msgs::msg::PointStamped robot_point;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            robot_point = transformToRobotFrame(camera_point);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Create and publish object position</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            geometry_msgs::msg::PointStamped object_position;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            object_position.header = robot_point.header;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            object_position.point = robot_point.point;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Add object label as metadata (in a real system, you might publish this separately)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            RCLCPP_INFO(this-&gt;get_logger(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &quot;Detected %s at position: (%.2f, %.2f, %.2f) with confidence %.2f&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                detection.label.c_str(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                object_position.point.x,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                object_position.point.y,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                object_position.point.z,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                detection.confidence</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            object_pose_pub_-&gt;publish(object_position);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    geometry_msgs::msg::PointStamped pixelToCameraFrame(const geometry_msgs::msg::PointStamped&amp; pixel_point)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        geometry_msgs::msg::PointStamped camera_point;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        camera_point.header = pixel_point.header;  // Keep same timestamp/frame initially</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Convert pixel coordinates to normalized coordinates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        double x_norm = (pixel_point.point.x - camera_info_.k[2]) / camera_info_.k[0];  // cx, fx</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        double y_norm = (pixel_point.point.y - camera_info_.k[5]) / camera_info_.k[4];  // cy, fy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // For this example, assume depth is known from other sources</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // In practice, you&#x27;d get depth from stereo, LIDAR, or depth sensor</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        double depth = estimateDepth(pixel_point.point.x, pixel_point.point.y);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        camera_point.point.x = x_norm * depth;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        camera_point.point.y = y_norm * depth;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        camera_point.point.z = depth;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return camera_point;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    geometry_msgs::msg::PointStamped transformToRobotFrame(const geometry_msgs::msg::PointStamped&amp; camera_point)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        geometry_msgs::msg::PointStamped robot_point;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        try {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Transform from camera frame to robot base frame</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            tf_buffer_.transform(camera_point, robot_point, &quot;base_link&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        } catch (tf2::TransformException&amp; ex) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            RCLCPP_ERROR(this-&gt;get_logger(), &quot;Transform failed: %s&quot;, ex.what());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return camera_point;  // Return original if transform fails</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return robot_point;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    double estimateDepth(double u, double v)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Placeholder depth estimation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // In a real system, this would come from:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 1. Stereo vision</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 2. Depth sensor (RGB-D camera, LIDAR)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 3. Monocular depth estimation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 4. Object size-based estimation (if object size is known)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // For this example, return a fixed depth</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // A more realistic approach would use stereo disparity or other depth sources</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return 1.0;  // 1 meter depth as placeholder</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void cameraInfoCallback(const sensor_msgs::msg::CameraInfo::SharedPtr msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        camera_info_ = *msg;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        camera_info_received_ = true;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Subscription&lt;isaac_ros_detectnet_interfaces::msg::DetectionArray&gt;::SharedPtr detection_sub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Subscription&lt;sensor_msgs::msg::CameraInfo&gt;::SharedPtr camera_info_sub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Publisher&lt;geometry_msgs::msg::PointStamped&gt;::SharedPtr object_pose_pub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tf2_ros::Buffer tf_buffer_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::shared_ptr&lt;tf2_ros::TransformListener&gt; tf_listener_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sensor_msgs::msg::CameraInfo camera_info_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    bool camera_info_received_ = false;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    bool has_camera_to_robot_tf_ = false;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    const double confidence_threshold_ = 0.7;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">};</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### 2. Semantic Segmentation for Object Localization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```cpp</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;rclcpp/rclcpp.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;sensor_msgs/msg/image.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;cv_bridge/cv_bridge.h&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;opencv2/opencv.hpp&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class SemanticSegmentationNode : public rclcpp::Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">public:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    SemanticSegmentationNode() : Node(&quot;semantic_segmentation_node&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        image_sub_ = this-&gt;create_subscription&lt;sensor_msgs::msg::Image&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;image_input&quot;, 10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::bind(&amp;SemanticSegmentationNode::imageCallback, this, std::placeholders::_1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        segmentation_pub_ = this-&gt;create_publisher&lt;sensor_msgs::msg::Image&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;segmentation_output&quot;, 10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">private:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void imageCallback(const sensor_msgs::msg::Image::SharedPtr image_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Convert ROS image to OpenCV</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv_bridge::CvImagePtr cv_ptr;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        try {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            cv_ptr = cv_bridge::toCvCopy(image_msg, sensor_msgs::image_encodings::BGR8);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        } catch (cv_bridge::Exception&amp; e) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            RCLCPP_ERROR(this-&gt;get_logger(), &quot;cv_bridge exception: %s&quot;, e.what());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Run semantic segmentation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv::Mat segmentation_mask = runSegmentationInference(cv_ptr-&gt;image);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Create result image with segmentation overlay</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv::Mat result_image = createSegmentationOverlay(cv_ptr-&gt;image, segmentation_mask);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Publish segmentation result</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        publishSegmentationResult(result_image, image_msg-&gt;header);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cv::Mat runSegmentationInference(const cv::Mat&amp; image)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Placeholder for actual segmentation inference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // This would typically use a model like DeepLab, SegNet, or similar</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // For Isaac ROS, this might use Isaac ROS Segmentation packages</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv::Mat segmentation_mask;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // In a real implementation, this would:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 1. Preprocess image for the segmentation model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 2. Run inference using TensorRT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 3. Post-process to get class labels for each pixel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 4. Return a mask where each pixel value represents the class ID</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // For this example, return a dummy mask</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        segmentation_mask = cv::Mat::zeros(image.size(), CV_8UC1);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Simulate detection of a few classes in specific regions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv::rectangle(segmentation_mask, cv::Rect(100, 100, 200, 150), cv::Scalar(1), -1); // Class 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv::rectangle(segmentation_mask, cv::Rect(300, 200, 150, 100), cv::Scalar(2), -1); // Class 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return segmentation_mask;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cv::Mat createSegmentationOverlay(const cv::Mat&amp; original_image, const cv::Mat&amp; segmentation_mask)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv::Mat overlay = original_image.clone();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Define colors for different classes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::vector&lt;cv::Vec3b&gt; class_colors = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            cv::Vec3b(0, 0, 0),      // Class 0: background (black)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            cv::Vec3b(255, 0, 0),    // Class 1: red</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            cv::Vec3b(0, 255, 0),    // Class 2: green</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            cv::Vec3b(0, 0, 255),    // Class 3: blue</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            cv::Vec3b(255, 255, 0),  // Class 4: cyan</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            cv::Vec3b(255, 0, 255),  // Class 5: magenta</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        };</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Create overlay with transparency</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for (int y = 0; y &lt; segmentation_mask.rows; y++) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            for (int x = 0; x &lt; segmentation_mask.cols; x++) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                int class_id = segmentation_mask.at&lt;uchar&gt;(y, x);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                if (class_id &gt; 0 &amp;&amp; class_id &lt; class_colors.size()) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    // Blend original color with class color</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    cv::Vec3b&amp; pixel = overlay.at&lt;cv::Vec3b&gt;(y, x);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    cv::Vec3b class_color = class_colors[class_id];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    // Simple blending (50% original, 50% class color)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    pixel = 0.5 * pixel + 0.5 * class_color;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return overlay;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void publishSegmentationResult(const cv::Mat&amp; result_image, const std_msgs::msg::Header&amp; header)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv_bridge::CvImage cv_image;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv_image.header = header;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv_image.encoding = sensor_msgs::image_encodings::BGR8;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv_image.image = result_image;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        segmentation_pub_-&gt;publish(*cv_image.toImageMsg());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Subscription&lt;sensor_msgs::msg::Image&gt;::SharedPtr image_sub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Publisher&lt;sensor_msgs::msg::Image&gt;::SharedPtr segmentation_pub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">};</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## Isaac Sim Perception Integration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### Isaac Sim Perception Configuration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Isaac Sim perception setup</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import omni</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from omni.isaac.core import World</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from omni.isaac.core.utils.stage import add_reference_to_stage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from omni.isaac.core.utils.nucleus import get_assets_root_path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from omni.isaac.sensor import Camera</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from omni.isaac.range_sensor import RotatingLidarPhysX</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class IsaacSimPerception:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.world = World(stage_units_in_meters=1.0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.setup_perception_sensors()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def setup_perception_sensors(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Add a robot to the scene</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        assets_root_path = get_assets_root_path()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if assets_root_path is None:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            print(&quot;Could not find Isaac Sim assets&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Add a simple robot with sensors</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        robot_path = assets_root_path + &quot;/Isaac/Robots/Carter/carter_navigate.usd&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        add_reference_to_stage(usd_path=robot_path, prim_path=&quot;/World/Carter&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Add a camera sensor</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.camera = Camera(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            prim_path=&quot;/World/Carter/chassis/camera&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            frequency=30,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            resolution=(640, 480)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Add a LIDAR sensor</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.lidar = RotatingLidarPhysX(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            prim_path=&quot;/World/Carter/chassis/lidar&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            translation=np.array([0.0, 0.0, 0.25]),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            config=&quot;Carter&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            rotation_frequency=10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            samples_per_scan=1080</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Initialize the world</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.world.reset()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def get_sensor_data(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Get camera data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        rgb_data = self.camera.get_rgb()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        depth_data = self.camera.get_depth()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        seg_data = self.camera.get_semantic_segmentation()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Get LIDAR data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        lidar_data = self.lidar.get_linear_depth_data()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;rgb&#x27;: rgb_data,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;depth&#x27;: depth_data,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;segmentation&#x27;: seg_data,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;lidar&#x27;: lidar_data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def run_perception_pipeline(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Main perception loop</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        while not self.world.is_stopped():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.world.step(render=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # Get sensor data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            sensor_data = self.get_sensor_data()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # Process perception data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            objects = self.detect_objects(sensor_data)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # Localize objects in world coordinates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            object_poses = self.localize_objects(objects, sensor_data)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # Print results</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.print_perception_results(object_poses)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def detect_objects(self, sensor_data):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Placeholder for object detection</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # In Isaac Sim, this would interface with Isaac ROS perception packages</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # or use built-in synthetic data generation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # For this example, return simulated detections</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        objects = [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            {&#x27;class&#x27;: &#x27;box&#x27;, &#x27;confidence&#x27;: 0.95, &#x27;bbox&#x27;: [100, 100, 200, 150]},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            {&#x27;class&#x27;: &#x27;cylinder&#x27;, &#x27;confidence&#x27;: 0.89, &#x27;bbox&#x27;: [300, 200, 150, 100]}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return objects</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def localize_objects(self, objects, sensor_data):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Convert 2D detections to 3D world coordinates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # This would use depth information and camera parameters</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        object_poses = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for obj in objects:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # Convert 2D bbox center to 3D using depth</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            center_x = (obj[&#x27;bbox&#x27;][0] + obj[&#x27;bbox&#x27;][2]) // 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            center_y = (obj[&#x27;bbox&#x27;][1] + obj[&#x27;bbox&#x27;][3]) // 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # Get depth at center point</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            depth = sensor_data[&#x27;depth&#x27;][center_y, center_x]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if depth &lt; 10.0:  # Valid depth check</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                # Convert pixel coordinates to world coordinates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                # This requires camera intrinsic parameters</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                world_pos = self.pixel_to_world(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    center_x, center_y, depth,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    self.camera.prim.GetAttribute(&quot;xformOp:transform&quot;).Get()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                object_poses.append({</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &#x27;class&#x27;: obj[&#x27;class&#x27;],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &#x27;position&#x27;: world_pos,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &#x27;confidence&#x27;: obj[&#x27;confidence&#x27;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                })</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return object_poses</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def pixel_to_world(self, u, v, depth, camera_transform):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Convert pixel coordinates to world coordinates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # This is a simplified version - in practice, you&#x27;d use camera intrinsics</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Camera intrinsic parameters (these would come from camera config)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        fx = 616.363  # Focal length x</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        fy = 616.363  # Focal length y</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cx = 313.071  # Principal point x</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cy = 245.091  # Principal point y</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Convert to camera coordinates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x_cam = (u - cx) * depth / fx</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        y_cam = (v - cy) * depth / fy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        z_cam = depth</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Transform to world coordinates using camera pose</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # (simplified - would need proper transformation matrix)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x_world = x_cam  # Simplified</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        y_world = y_cam</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        z_world = z_cam</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return [x_world, y_world, z_world]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def print_perception_results(self, object_poses):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        print(&quot;Perception Results:&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for obj in object_poses:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            print(f&quot;  {obj[&#x27;class&#x27;]}: ({obj[&#x27;position&#x27;][0]:.2f}, {obj[&#x27;position&#x27;][1]:.2f}, {obj[&#x27;position&#x27;][2]:.2f}), conf: {obj[&#x27;confidence&#x27;]:.2f}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## Practical Examples</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### Example 1: Person Detection and Localization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```cpp</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// Complete example for detecting and localizing people</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class PersonDetectionNode : public rclcpp::Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">public:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    PersonDetectionNode() : Node(&quot;person_detection_node&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Subscribe to camera image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        image_sub_ = this-&gt;create_subscription&lt;sensor_msgs::msg::Image&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;camera/image_raw&quot;, 10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::bind(&amp;PersonDetectionNode::imageCallback, this, std::placeholders::_1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Subscribe to camera info</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        camera_info_sub_ = this-&gt;create_subscription&lt;sensor_msgs::msg::CameraInfo&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;camera/camera_info&quot;, 10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::bind(&amp;PersonDetectionNode::cameraInfoCallback, this, std::placeholders::_1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Publisher for person positions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        person_pub_ = this-&gt;create_publisher&lt;geometry_msgs::msg::PointStamped&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;person_position&quot;, 10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Publisher for visualization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        viz_pub_ = this-&gt;create_publisher&lt;sensor_msgs::msg::Image&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;person_detection_viz&quot;, 10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">private:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void imageCallback(const sensor_msgs::msg::Image::SharedPtr image_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (!camera_info_received_) return;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Convert to OpenCV</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv_bridge::CvImagePtr cv_ptr;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        try {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            cv_ptr = cv_bridge::toCvCopy(image_msg, sensor_msgs::image_encodings::BGR8);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        } catch (cv_bridge::Exception&amp; e) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            RCLCPP_ERROR(this-&gt;get_logger(), &quot;cv_bridge exception: %s&quot;, e.what());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Run person detection</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::vector&lt;PersonDetection&gt; persons = detectPersons(cv_ptr-&gt;image);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Process each detected person</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for (const auto&amp; person : persons) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if (person.confidence &gt; 0.8) {  // Confidence threshold</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                // Localize person in 3D space</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                geometry_msgs::msg::PointStamped person_3d = localizePerson(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    person, image_msg-&gt;header</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                // Publish person position</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                person_pub_-&gt;publish(person_3d);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                // Add to visualization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                cv::rectangle(cv_ptr-&gt;image, person.bbox, cv::Scalar(0, 255, 0), 2);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                std::string label = &quot;Person: &quot; + std::to_string(person.confidence);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                cv::putText(cv_ptr-&gt;image, label,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                           cv::Point(person.bbox.x, person.bbox.y - 10),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                           cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 255, 0), 1);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Publish visualization image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        viz_pub_-&gt;publish(*cv_ptr-&gt;toImageMsg());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::vector&lt;PersonDetection&gt; detectPersons(const cv::Mat&amp; image)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::vector&lt;PersonDetection&gt; detections;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // In a real implementation, this would run a DNN model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // such as YOLO, SSD MobileNet, or Isaac ROS DetectNet</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // For this example, we&#x27;ll use OpenCV&#x27;s HOG descriptor</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv::HOGDescriptor hog;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        hog.setSVMDetector(cv::HOGDescriptor::getDefaultPeopleDetector());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::vector&lt;cv::Rect&gt; found_locations;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::vector&lt;double&gt; found_weights;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        hog.detectMultiScale(image, found_locations, found_weights, 0, cv::Size(8,8), cv::Size(32,32), 1.05, 2, false);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for (size_t i = 0; i &lt; found_locations.size(); ++i) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            PersonDetection detection;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            detection.bbox = found_locations[i];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            detection.confidence = found_weights[i];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            detection.center_x = detection.bbox.x + detection.bbox.width / 2.0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            detection.center_y = detection.bbox.y + detection.bbox.height / 2.0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            detections.push_back(detection);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return detections;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    geometry_msgs::msg::PointStamped localizePerson(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        const PersonDetection&amp; person,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        const std_msgs::msg::Header&amp; header)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        geometry_msgs::msg::PointStamped person_3d;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        person_3d.header = header;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Estimate depth using simple heuristics</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // In practice, you&#x27;d use stereo vision or depth sensor</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        double depth = estimatePersonDepth(person.bbox.height);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Convert pixel to 3D coordinates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        double x_norm = (person.center_x - camera_info_.k[2]) / camera_info_.k[0];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        double y_norm = (person.center_y - camera_info_.k[5]) / camera_info_.k[4];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        person_3d.point.x = x_norm * depth;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        person_3d.point.y = y_norm * depth;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        person_3d.point.z = depth;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return person_3d;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    double estimatePersonDepth(int bbox_height)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Simple depth estimation based on bounding box height</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Assumes average person height is ~1.7m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // height_in_pixels = (focal_length * real_height) / depth</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // So depth = (focal_length * real_height) / height_in_pixels</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        double focal_length = camera_info_.k[0];  // fx</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        double real_person_height = 1.7;  // meters</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        double pixel_height = static_cast&lt;double&gt;(bbox_height);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return (focal_length * real_person_height) / pixel_height;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    struct PersonDetection {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv::Rect bbox;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        double confidence;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        double center_x, center_y;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    };</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void cameraInfoCallback(const sensor_msgs::msg::CameraInfo::SharedPtr msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        camera_info_ = *msg;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        camera_info_received_ = true;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Subscription&lt;sensor_msgs::msg::Image&gt;::SharedPtr image_sub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Subscription&lt;sensor_msgs::msg::CameraInfo&gt;::SharedPtr camera_info_sub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Publisher&lt;geometry_msgs::msg::PointStamped&gt;::SharedPtr person_pub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Publisher&lt;sensor_msgs::msg::Image&gt;::SharedPtr viz_pub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sensor_msgs::msg::CameraInfo camera_info_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    bool camera_info_received_ = false;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">};</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### Example 2: Object Detection with Isaac ROS and Isaac Sim</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Isaac Sim + Isaac ROS integration example</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import rclpy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from rclpy.node import Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from sensor_msgs.msg import Image, CameraInfo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from isaac_ros_detectnet_interfaces.msg import DetectionArray</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from geometry_msgs.msg import PointStamped</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import cv2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from cv_bridge import CvBridge</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class IsaacPerceptionPipeline(Node):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super().__init__(&#x27;isaac_perception_pipeline&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # ROS 2 interface</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.bridge = CvBridge()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Publishers and subscribers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.image_sub = self.create_subscription(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            Image, &#x27;/camera/image_raw&#x27;, self.image_callback, 10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.camera_info_sub = self.create_subscription(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            CameraInfo, &#x27;/camera/camera_info&#x27;, self.camera_info_callback, 10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.detection_sub = self.create_subscription(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            DetectionArray, &#x27;/detectnet/detections&#x27;, self.detection_callback, 10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.object_pub = self.create_publisher(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            PointStamped, &#x27;/detected_object_position&#x27;, 10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.viz_pub = self.create_publisher(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            Image, &#x27;/perception_visualization&#x27;, 10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Storage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.camera_info = None</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.latest_image = None</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def image_callback(self, msg):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.latest_image = msg</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def camera_info_callback(self, msg):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.camera_info = msg</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def detection_callback(self, msg):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if self.latest_image is None or self.camera_info is None:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Convert ROS image to OpenCV</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv_image = self.bridge.imgmsg_to_cv2(self.latest_image, &quot;bgr8&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Process detections</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for detection in msg.detections:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if detection.confidence &gt; 0.7:  # Confidence threshold</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                # Localize object in 3D</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                object_3d = self.localize_object_3d(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    detection.bbox.center.x,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    detection.bbox.center.y,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    detection</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                # Publish 3D position</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                self.object_pub.publish(object_3d)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                # Draw bounding box on image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                pt1 = (int(detection.bbox.center.x - detection.bbox.size_x/2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                       int(detection.bbox.center.y - detection.bbox.size_y/2))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                pt2 = (int(detection.bbox.center.x + detection.bbox.size_x/2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                       int(detection.bbox.center.y + detection.bbox.size_y/2))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                cv2.rectangle(cv_image, pt1, pt2, (0, 255, 0), 2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                cv2.putText(cv_image, f&quot;{detection.label}: {detection.confidence:.2f}&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                           (pt1[0], pt1[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Publish visualization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        viz_msg = self.bridge.cv2_to_imgmsg(cv_image, encoding=&quot;bgr8&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        viz_msg.header = self.latest_image.header</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.viz_pub.publish(viz_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def localize_object_3d(self, x_2d, y_2d, detection):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # This is a simplified example</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # In practice, you&#x27;d use depth information from stereo or depth sensor</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        point_3d = PointStamped()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        point_3d.header = detection.header</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Estimate depth based on object size or use depth map</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # For this example, assume a fixed depth of 2 meters</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        estimated_depth = 2.0  # meters</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Convert 2D pixel coordinates to 3D using camera intrinsics</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if self.camera_info:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            fx = self.camera_info.k[0]  # Focal length x</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            fy = self.camera_info.k[4]  # Focal length y</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            cx = self.camera_info.k[2]  # Principal point x</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            cy = self.camera_info.k[5]  # Principal point y</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            point_3d.point.x = (x_2d - cx) * estimated_depth / fx</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            point_3d.point.y = (y_2d - cy) * estimated_depth / fy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            point_3d.point.z = estimated_depth</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return point_3d</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def main(args=None):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclpy.init(args=args)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    perception_node = IsaacPerceptionPipeline()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        rclpy.spin(perception_node)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    except KeyboardInterrupt:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        pass</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    finally:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        perception_node.destroy_node()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        rclpy.shutdown()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if __name__ == &#x27;__main__&#x27;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    main()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## Performance Optimization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### 1. TensorRT Optimization for Deep Learning Models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```cpp</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// Example of TensorRT optimization for perception</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;NvInfer.h&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;cuda_runtime_api.h&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class OptimizedPerceptionNode : public rclcpp::Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">public:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    OptimizedPerceptionNode() : Node(&quot;optimized_perception_node&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Initialize TensorRT engine</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        initializeTensorRTEngine();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">private:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void initializeTensorRTEngine()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // This would load a pre-built TensorRT engine</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // for optimized inference of perception models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // The engine would be built offline from ONNX models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::vector&lt;Detection&gt; runOptimizedInference(const cv::Mat&amp; image)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Run inference using TensorRT for maximum performance</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // This would include:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 1. Memory management for GPU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 2. Batch processing</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 3. Asynchronous execution</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 4. Proper input/output binding</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::vector&lt;Detection&gt; detections;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Implementation would go here</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return detections;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    nvinfer1::ICudaEngine* engine_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    nvinfer1::IExecutionContext* context_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cudaStream_t stream_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void* buffers_[2];  // Input and output buffers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">};</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### 2. Multi-Threaded Perception Pipeline</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```cpp</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;thread&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;queue&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;mutex&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;condition_variable&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class MultiThreadedPerceptionNode : public rclcpp::Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">public:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    MultiThreadedPerceptionNode() : Node(&quot;multithreaded_perception_node&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Create threads for different perception tasks</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        detection_thread_ = std::thread(&amp;MultiThreadedPerceptionNode::detectionLoop, this);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        localization_thread_ = std::thread(&amp;MultiThreadedPerceptionNode::localizationLoop, this);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Subscribe to image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        image_sub_ = this-&gt;create_subscription&lt;sensor_msgs::msg::Image&gt;(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;image_input&quot;, 10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::bind(&amp;MultiThreadedPerceptionNode::imageCallback, this, std::placeholders::_1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        );</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ~MultiThreadedPerceptionNode()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        running_ = false;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (detection_thread_.joinable()) detection_thread_.join();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (localization_thread_.joinable()) localization_thread_.join();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">private:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void imageCallback(const sensor_msgs::msg::Image::SharedPtr image_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::lock_guard&lt;std::mutex&gt; lock(image_queue_mutex_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        image_queue_.push(image_msg);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (image_queue_.size() &gt; max_queue_size_) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            image_queue_.pop();  // Drop oldest if queue is full</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        image_queue_cond_.notify_one();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void detectionLoop()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        while (running_) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            sensor_msgs::msg::Image::SharedPtr image_msg;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                std::unique_lock&lt;std::mutex&gt; lock(image_queue_mutex_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                image_queue_cond_.wait(lock, [this] { return !image_queue_.empty() || !running_; });</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                if (!running_) break;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                image_msg = image_queue_.front();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                image_queue_.pop();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Run object detection</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            auto detections = runDetection(image_msg);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Add to detection queue</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                std::lock_guard&lt;std::mutex&gt; lock(detection_queue_mutex_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                detection_queue_.push(std::make_pair(image_msg-&gt;header, detections));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            detection_queue_cond_.notify_one();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void localizationLoop()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        while (running_) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std_msgs::msg::Header header;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::vector&lt;Detection&gt; detections;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                std::unique_lock&lt;std::mutex&gt; lock(detection_queue_mutex_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                detection_queue_cond_.wait(lock, [this] { return !detection_queue_.empty() || !running_; });</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                if (!running_) break;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                auto detection_pair = detection_queue_.front();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                header = detection_pair.first;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                detections = detection_pair.second;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                detection_queue_.pop();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Run localization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            auto object_positions = runLocalization(detections, header);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Publish results</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            publishResults(object_positions);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::vector&lt;Detection&gt; runDetection(const sensor_msgs::msg::Image::SharedPtr image_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Run object detection on the image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Implementation would go here</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return std::vector&lt;Detection&gt;();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::vector&lt;ObjectPosition&gt; runLocalization(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        const std::vector&lt;Detection&gt;&amp; detections,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        const std_msgs::msg::Header&amp; header)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Localize objects in 3D space</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Implementation would go here</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return std::vector&lt;ObjectPosition&gt;();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void publishResults(const std::vector&lt;ObjectPosition&gt;&amp; positions)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Publish localization results</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Implementation would go here</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    struct Detection {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::string label;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float confidence;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv::Rect bbox;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    };</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    struct ObjectPosition {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::string label;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        geometry_msgs::msg::Point position;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float confidence;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    };</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclcpp::Subscription&lt;sensor_msgs::msg::Image&gt;::SharedPtr image_sub_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // Image processing queue</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::queue&lt;sensor_msgs::msg::Image::SharedPtr&gt; image_queue_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::mutex image_queue_mutex_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::condition_variable image_queue_cond_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // Detection queue</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::queue&lt;std::pair&lt;std_msgs::msg::Header, std::vector&lt;Detection&gt;&gt;&gt; detection_queue_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::mutex detection_queue_mutex_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::condition_variable detection_queue_cond_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::thread detection_thread_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::thread localization_thread_;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::atomic&lt;bool&gt; running_{true};</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    const size_t max_queue_size_ = 5;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">};</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## Best Practices</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### 1. Confidence Thresholding</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Always use confidence thresholds to filter out low-quality detections:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Set appropriate thresholds based on your application requirements</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Consider using adaptive thresholds based on scene complexity</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Validate detections with geometric consistency checks</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### 2. Multi-Sensor Fusion</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Combine data from multiple sensors for robust perception:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Fuse camera, LIDAR, and radar data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Use Kalman filters or particle filters for tracking</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Implement sensor validation and fault detection</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### 3. Performance Monitoring</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Monitor perception performance in real-time:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Track inference time and frame rates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Monitor memory and GPU usage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Log detection accuracy and false positive rates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## Exercise</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Create a complete perception pipeline that includes:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. Object detection using Isaac ROS DetectNet</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. 3D localization using stereo vision or depth information</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Multi-threaded processing for real-time performance</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. Integration with Isaac Sim for testing</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5. Visualization of detection results</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">6. Performance evaluation metrics</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Test your pipeline with various objects in different lighting conditions and evaluate its accuracy and performance.</span><br></span></code></pre></div></div></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/isaac-sim-fundamentals"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Isaac Sim Fundamentals</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-perception/navigation-planning-obstacle-avoidance"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Navigation Planning and Obstacle Avoidance Examples</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction-to-object-detection-in-robotics" class="table-of-contents__link toc-highlight">Introduction to Object Detection in Robotics</a></li><li><a href="#isaac-ros-perception-pipeline" class="table-of-contents__link toc-highlight">Isaac ROS Perception Pipeline</a><ul><li><a href="#overview-of-isaac-ros-perception-stack" class="table-of-contents__link toc-highlight">Overview of Isaac ROS Perception Stack</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Content</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Physical-AI-Humanoid-Robotics-Book/">Introduction</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/your-username/physical-ai-humanoid-robotics" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Physical AI & Humanoid Robotics Book. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>